{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Control\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the second project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893) program.\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing the necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Reacher.app\"`\n",
    "- **Windows** (x86): `\"path/to/Reacher_Windows_x86/Reacher.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Reacher_Windows_x86_64/Reacher.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Reacher_Linux/Reacher.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Reacher_Linux/Reacher.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Reacher_Linux_NoVis/Reacher.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Reacher_Linux_NoVis/Reacher.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Reacher.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Reacher.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = UnityEnvironment(file_name='...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "In this environment, a double-jointed arm can move to target locations. A reward of `+0.1` is provided for each step that the agent's hand is in the goal location. Thus, the goal of your agent is to maintain its position at the target location for as many time steps as possible.\n",
    "\n",
    "The observation space consists of `33` variables corresponding to position, rotation, velocity, and angular velocities of the arm.  Each action is a vector with four numbers, corresponding to torque applicable to two joints.  Every entry in the action vector must be a number between `-1` and `1`.\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Once this cell is executed, you will watch the agent's performance, if it selects an action at random with each time step.  A window should pop up that allows you to observe the agent, as it moves through the environment.  \n",
    "\n",
    "Of course, as part of the project, you'll have to change the code so that the agent is able to use its experience to gradually choose better actions when interacting with the environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "while True:\n",
    "    actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "    actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "    env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "    next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "    rewards = env_info.rewards                         # get reward (for each agent)\n",
    "    dones = env_info.local_done                        # see if episode finished\n",
    "    scores += env_info.rewards                         # update the score (for each agent)\n",
    "    states = next_states                               # roll over states to next time step\n",
    "    if np.any(dones):                                  # exit loop if episode finished\n",
    "        break\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start from Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\ANDREISolomon\\\\PycharmProjects\\\\deep-reinforcement-learning\\\\p2_continuous-control\\\\DRL-Continuous-Control', 'C:\\\\Users\\\\ANDREISolomon\\\\Miniconda3\\\\envs\\\\stan_env\\\\python37.zip', 'C:\\\\Users\\\\ANDREISolomon\\\\Miniconda3\\\\envs\\\\stan_env\\\\DLLs', 'C:\\\\Users\\\\ANDREISolomon\\\\Miniconda3\\\\envs\\\\stan_env\\\\lib', 'C:\\\\Users\\\\ANDREISolomon\\\\Miniconda3\\\\envs\\\\stan_env', '', 'C:\\\\Users\\\\ANDREISolomon\\\\AppData\\\\Roaming\\\\Python\\\\Python37\\\\site-packages', 'c:\\\\users\\\\andreisolomon\\\\appdata\\\\local\\\\programs\\\\python\\\\python37\\\\lib\\\\site-packages\\\\matplotlib-3.1.0rc1-py3.7-win-amd64.egg', 'c:\\\\users\\\\andreisolomon\\\\appdata\\\\local\\\\programs\\\\python\\\\python37\\\\lib\\\\site-packages\\\\python_dateutil-2.8.0-py3.7.egg', 'c:\\\\users\\\\andreisolomon\\\\appdata\\\\local\\\\programs\\\\python\\\\python37\\\\lib\\\\site-packages\\\\pyparsing-2.4.0-py3.7.egg', 'c:\\\\users\\\\andreisolomon\\\\appdata\\\\local\\\\programs\\\\python\\\\python37\\\\lib\\\\site-packages\\\\kiwisolver-1.1.0-py3.7-win-amd64.egg', 'c:\\\\users\\\\andreisolomon\\\\appdata\\\\local\\\\programs\\\\python\\\\python37\\\\lib\\\\site-packages\\\\cycler-0.10.0-py3.7.egg', 'c:\\\\users\\\\andreisolomon\\\\appdata\\\\local\\\\programs\\\\python\\\\python37\\\\lib\\\\site-packages\\\\six-1.12.0-py3.7.egg', 'c:\\\\users\\\\andreisolomon\\\\appdata\\\\local\\\\programs\\\\python\\\\python37\\\\lib\\\\site-packages', 'C:\\\\Users\\\\ANDREISolomon\\\\Miniconda3\\\\envs\\\\stan_env\\\\lib\\\\site-packages', 'c:\\\\users\\\\andreisolomon\\\\pycharmprojects\\\\deep-reinforcement-learning\\\\lunarlander\\\\gym', 'c:\\\\users\\\\andreisolomon\\\\appdata\\\\local\\\\programs\\\\python\\\\python37\\\\lib\\\\site-packages\\\\IPython\\\\extensions', 'C:\\\\Users\\\\ANDREISolomon\\\\.ipython', 'C:/Users/ANDREISolomon/PycharmProjects/deep-reinforcement-learning/python']\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "sys.path\n",
    "sys.path.append(os.path.join(\"C:/Users/ANDREISolomon/PycharmProjects/deep-reinforcement-learning/python\"))\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "\n",
    "# select this option to load version 1 (with a single agent) of the environment\n",
    "# env = UnityEnvironment(file_name='/data/Reacher_One_Linux_NoVis/Reacher_One_Linux_NoVis.x86_64')\n",
    "\n",
    "# select this option to load version 2 (with 20 agents) of the environment\n",
    "env = UnityEnvironment(file_name='./20_Reacher_Windows_x86_64/Reacher.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 20\n",
      "Size of each action: 4\n",
      "There are 20 agents. Each observes a state with length: 33\n",
      "The state for the first agent looks like: [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "  1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  5.75471878e+00 -1.00000000e+00\n",
      "  5.55726624e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -1.68164849e-01]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ddpg_agent import Agent\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import time\n",
    "from workspace_utils import active_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1, Average Score: 0.80, Max Score: 1.58, Min Score: 0.25, Time per Episode: 65.10\n",
      "Epsilon: 0.9996079999999887 and Memory size: 10020\n",
      "Episode 2, Average Score: 0.69, Max Score: 1.26, Min Score: 0.00, Time per Episode: 63.75\n",
      "Epsilon: 0.9992079999999772 and Memory size: 20040\n",
      "Episode 3, Average Score: 0.80, Max Score: 1.93, Min Score: 0.13, Time per Episode: 62.56\n",
      "Epsilon: 0.9988079999999657 and Memory size: 30060\n",
      "Episode 4, Average Score: 1.02, Max Score: 3.12, Min Score: 0.61, Time per Episode: 64.17\n",
      "Epsilon: 0.9984079999999542 and Memory size: 40080\n",
      "Episode 5, Average Score: 1.17, Max Score: 4.68, Min Score: 0.33, Time per Episode: 63.02\n",
      "Epsilon: 0.9980079999999427 and Memory size: 50100\n",
      "Episode 6, Average Score: 1.29, Max Score: 4.42, Min Score: 0.15, Time per Episode: 64.28\n",
      "Epsilon: 0.9976079999999312 and Memory size: 60120\n",
      "Episode 7, Average Score: 1.41, Max Score: 3.19, Min Score: 1.20, Time per Episode: 65.81\n",
      "Epsilon: 0.9972079999999197 and Memory size: 70140\n",
      "Episode 8, Average Score: 1.56, Max Score: 5.35, Min Score: 1.04, Time per Episode: 67.12\n",
      "Epsilon: 0.9968079999999082 and Memory size: 80160\n",
      "Episode 9, Average Score: 1.68, Max Score: 5.17, Min Score: 1.06, Time per Episode: 64.93\n",
      "Epsilon: 0.9964079999998967 and Memory size: 90180\n",
      "Episode 10, Average Score: 1.87, Max Score: 5.81, Min Score: 1.89, Time per Episode: 65.27\n",
      "Epsilon: 0.9960079999998852 and Memory size: 100200\n",
      "Episode 11, Average Score: 2.08, Max Score: 7.88, Min Score: 1.81, Time per Episode: 65.90\n",
      "Epsilon: 0.9956071999998737 and Memory size: 110200\n",
      "Episode 12, Average Score: 2.29, Max Score: 7.63, Min Score: 2.39, Time per Episode: 65.39\n",
      "Epsilon: 0.9952063999998622 and Memory size: 120200\n",
      "Episode 13, Average Score: 2.42, Max Score: 6.42, Min Score: 2.53, Time per Episode: 65.25\n",
      "Epsilon: 0.9948055999998506 and Memory size: 130200\n",
      "Episode 14, Average Score: 2.60, Max Score: 7.21, Min Score: 1.98, Time per Episode: 65.32\n",
      "Epsilon: 0.9944047999998391 and Memory size: 140200\n",
      "Episode 15, Average Score: 2.81, Max Score: 9.86, Min Score: 1.82, Time per Episode: 65.80\n",
      "Epsilon: 0.9940039999998276 and Memory size: 150200\n",
      "Episode 16, Average Score: 3.00, Max Score: 8.09, Min Score: 2.98, Time per Episode: 65.98\n",
      "Epsilon: 0.9936031999998161 and Memory size: 160200\n",
      "Episode 17, Average Score: 3.22, Max Score: 9.63, Min Score: 3.35, Time per Episode: 66.34\n",
      "Epsilon: 0.9932023999998045 and Memory size: 170200\n",
      "Episode 18, Average Score: 3.51, Max Score: 12.14, Min Score: 4.68, Time per Episode: 66.62\n",
      "Epsilon: 0.992801599999793 and Memory size: 180200\n",
      "Episode 19, Average Score: 3.79, Max Score: 13.71, Min Score: 5.27, Time per Episode: 66.81\n",
      "Epsilon: 0.9924007999997815 and Memory size: 190200\n",
      "Episode 20, Average Score: 4.02, Max Score: 12.29, Min Score: 6.23, Time per Episode: 67.74\n",
      "Epsilon: 0.99199999999977 and Memory size: 200200\n",
      "Episode 21, Average Score: 4.35, Max Score: 20.14, Min Score: 5.45, Time per Episode: 67.29\n",
      "Epsilon: 0.9915999999997585 and Memory size: 210220\n",
      "Episode 22, Average Score: 4.60, Max Score: 13.65, Min Score: 5.43, Time per Episode: 69.83\n",
      "Epsilon: 0.991199999999747 and Memory size: 220240\n",
      "Episode 23, Average Score: 4.97, Max Score: 18.25, Min Score: 8.26, Time per Episode: 68.69\n",
      "Epsilon: 0.9907999999997354 and Memory size: 230260\n",
      "Episode 24, Average Score: 5.37, Max Score: 21.86, Min Score: 8.71, Time per Episode: 68.52\n",
      "Epsilon: 0.990399999999724 and Memory size: 240280\n",
      "Episode 25, Average Score: 5.83, Max Score: 26.73, Min Score: 7.95, Time per Episode: 69.76\n",
      "Epsilon: 0.9899999999997124 and Memory size: 250300\n",
      "Episode 26, Average Score: 6.33, Max Score: 30.48, Min Score: 6.74, Time per Episode: 69.77\n",
      "Epsilon: 0.9895999999997009 and Memory size: 260320\n",
      "Episode 27, Average Score: 6.91, Max Score: 34.75, Min Score: 7.11, Time per Episode: 70.32\n",
      "Epsilon: 0.9891999999996894 and Memory size: 270340\n",
      "Episode 28, Average Score: 7.55, Max Score: 33.81, Min Score: 7.81, Time per Episode: 70.60\n",
      "Epsilon: 0.9887999999996779 and Memory size: 280360\n",
      "Episode 29, Average Score: 8.17, Max Score: 33.19, Min Score: 16.82, Time per Episode: 71.42\n",
      "Epsilon: 0.9883999999996664 and Memory size: 290380\n",
      "Episode 30, Average Score: 8.63, Max Score: 39.47, Min Score: 11.57, Time per Episode: 71.36\n",
      "Epsilon: 0.9879999999996549 and Memory size: 300400\n",
      "Episode 31, Average Score: 9.13, Max Score: 35.30, Min Score: 10.06, Time per Episode: 71.85\n",
      "Epsilon: 0.9875991999996434 and Memory size: 310400\n",
      "Episode 32, Average Score: 9.70, Max Score: 37.50, Min Score: 11.65, Time per Episode: 72.79\n",
      "Epsilon: 0.9871983999996319 and Memory size: 320400\n",
      "Episode 33, Average Score: 10.39, Max Score: 38.69, Min Score: 20.86, Time per Episode: 72.76\n",
      "Epsilon: 0.9867975999996204 and Memory size: 330400\n",
      "Episode 34, Average Score: 11.01, Max Score: 39.38, Min Score: 25.56, Time per Episode: 73.09\n",
      "Epsilon: 0.9863967999996088 and Memory size: 340400\n",
      "Episode 35, Average Score: 11.61, Max Score: 38.45, Min Score: 22.96, Time per Episode: 74.11\n",
      "Epsilon: 0.9859959999995973 and Memory size: 350400\n",
      "Episode 36, Average Score: 12.19, Max Score: 38.26, Min Score: 17.56, Time per Episode: 73.75\n",
      "Epsilon: 0.9855951999995858 and Memory size: 360400\n",
      "Episode 37, Average Score: 12.82, Max Score: 39.14, Min Score: 28.01, Time per Episode: 74.63\n",
      "Epsilon: 0.9851943999995743 and Memory size: 370400\n",
      "Episode 38, Average Score: 13.45, Max Score: 39.24, Min Score: 28.68, Time per Episode: 74.37\n",
      "Epsilon: 0.9847935999995627 and Memory size: 380400\n",
      "Episode 39, Average Score: 13.95, Max Score: 39.53, Min Score: 23.47, Time per Episode: 74.95\n",
      "Epsilon: 0.9843927999995512 and Memory size: 390400\n",
      "Episode 40, Average Score: 14.43, Max Score: 39.44, Min Score: 22.31, Time per Episode: 75.29\n",
      "Epsilon: 0.9839919999995397 and Memory size: 400400\n",
      "Episode 41, Average Score: 14.92, Max Score: 39.49, Min Score: 25.72, Time per Episode: 75.60\n",
      "Epsilon: 0.9835919999995282 and Memory size: 410420\n",
      "Episode 42, Average Score: 15.42, Max Score: 39.45, Min Score: 27.27, Time per Episode: 76.77\n",
      "Epsilon: 0.9831919999995167 and Memory size: 420440\n",
      "Episode 43, Average Score: 15.94, Max Score: 39.54, Min Score: 26.05, Time per Episode: 76.29\n",
      "Epsilon: 0.9827919999995052 and Memory size: 430460\n",
      "Episode 44, Average Score: 16.38, Max Score: 38.81, Min Score: 24.39, Time per Episode: 76.40\n",
      "Epsilon: 0.9823919999994937 and Memory size: 440480\n",
      "Episode 45, Average Score: 16.83, Max Score: 39.51, Min Score: 28.82, Time per Episode: 77.43\n",
      "Epsilon: 0.9819919999994822 and Memory size: 450500\n",
      "Episode 46, Average Score: 17.27, Max Score: 39.46, Min Score: 27.23, Time per Episode: 77.13\n",
      "Epsilon: 0.9815919999994707 and Memory size: 460520\n",
      "Episode 47, Average Score: 17.66, Max Score: 39.50, Min Score: 30.28, Time per Episode: 77.78\n",
      "Epsilon: 0.9811919999994592 and Memory size: 470540\n",
      "Episode 48, Average Score: 18.02, Max Score: 39.12, Min Score: 19.21, Time per Episode: 77.86\n",
      "Epsilon: 0.9807919999994477 and Memory size: 480560\n",
      "Episode 49, Average Score: 18.40, Max Score: 39.51, Min Score: 29.86, Time per Episode: 78.15\n",
      "Epsilon: 0.9803919999994362 and Memory size: 490580\n",
      "Episode 50, Average Score: 18.76, Max Score: 39.39, Min Score: 25.65, Time per Episode: 76.97\n",
      "Epsilon: 0.9799919999994247 and Memory size: 500600\n",
      "Episode 51, Average Score: 19.11, Max Score: 39.41, Min Score: 31.69, Time per Episode: 79.71\n",
      "Epsilon: 0.9795911999994131 and Memory size: 510600\n",
      "Episode 52, Average Score: 19.44, Max Score: 39.31, Min Score: 30.65, Time per Episode: 80.56\n",
      "Epsilon: 0.9791903999994016 and Memory size: 520600\n",
      "Episode 53, Average Score: 19.75, Max Score: 38.53, Min Score: 29.65, Time per Episode: 79.36\n",
      "Epsilon: 0.9787895999993901 and Memory size: 530600\n",
      "Episode 54, Average Score: 20.05, Max Score: 39.14, Min Score: 30.66, Time per Episode: 78.58\n",
      "Epsilon: 0.9783887999993786 and Memory size: 540600\n",
      "Episode 55, Average Score: 20.29, Max Score: 38.28, Min Score: 25.92, Time per Episode: 78.92\n",
      "Epsilon: 0.977987999999367 and Memory size: 550600\n",
      "Episode 56, Average Score: 20.50, Max Score: 38.92, Min Score: 25.04, Time per Episode: 79.54\n",
      "Epsilon: 0.9775871999993555 and Memory size: 560600\n",
      "Episode 57, Average Score: 20.77, Max Score: 38.82, Min Score: 28.84, Time per Episode: 80.10\n",
      "Epsilon: 0.977186399999344 and Memory size: 570600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 58, Average Score: 21.01, Max Score: 38.29, Min Score: 28.99, Time per Episode: 79.98\n",
      "Epsilon: 0.9767855999993325 and Memory size: 580600\n",
      "Episode 59, Average Score: 21.22, Max Score: 39.55, Min Score: 26.28, Time per Episode: 80.59\n",
      "Epsilon: 0.9763847999993209 and Memory size: 590600\n",
      "Episode 60, Average Score: 21.39, Max Score: 39.24, Min Score: 23.06, Time per Episode: 80.80\n",
      "Epsilon: 0.9759839999993094 and Memory size: 600600\n",
      "Episode 61, Average Score: 21.60, Max Score: 39.51, Min Score: 28.59, Time per Episode: 83.02\n",
      "Epsilon: 0.9755839999992979 and Memory size: 610620\n",
      "Episode 62, Average Score: 21.79, Max Score: 38.66, Min Score: 25.12, Time per Episode: 82.90\n",
      "Epsilon: 0.9751839999992864 and Memory size: 620640\n",
      "Episode 63, Average Score: 22.01, Max Score: 39.47, Min Score: 26.03, Time per Episode: 83.38\n",
      "Epsilon: 0.9747839999992749 and Memory size: 630660\n",
      "Episode 64, Average Score: 22.17, Max Score: 37.45, Min Score: 19.07, Time per Episode: 84.12\n",
      "Epsilon: 0.9743839999992634 and Memory size: 640680\n",
      "Episode 65, Average Score: 22.33, Max Score: 38.47, Min Score: 25.12, Time per Episode: 83.96\n",
      "Epsilon: 0.9739839999992519 and Memory size: 650700\n",
      "Episode 66, Average Score: 22.48, Max Score: 39.10, Min Score: 15.08, Time per Episode: 85.13\n",
      "Epsilon: 0.9735839999992404 and Memory size: 660720\n",
      "Episode 67, Average Score: 22.60, Max Score: 38.64, Min Score: 11.35, Time per Episode: 84.94\n",
      "Epsilon: 0.9731839999992289 and Memory size: 670740\n",
      "Episode 68, Average Score: 22.74, Max Score: 38.93, Min Score: 19.13, Time per Episode: 85.88\n",
      "Epsilon: 0.9727839999992174 and Memory size: 680760\n",
      "Episode 69, Average Score: 22.93, Max Score: 39.48, Min Score: 27.09, Time per Episode: 86.01\n",
      "Epsilon: 0.9723839999992059 and Memory size: 690780\n",
      "Episode 70, Average Score: 23.08, Max Score: 39.41, Min Score: 24.99, Time per Episode: 86.28\n",
      "Epsilon: 0.9719839999991944 and Memory size: 700800\n",
      "Episode 71, Average Score: 23.27, Max Score: 39.45, Min Score: 26.51, Time per Episode: 86.45\n",
      "Epsilon: 0.9715831999991829 and Memory size: 710800\n",
      "Episode 72, Average Score: 23.45, Max Score: 38.97, Min Score: 27.35, Time per Episode: 88.68\n",
      "Epsilon: 0.9711823999991713 and Memory size: 720800\n",
      "Episode 73, Average Score: 23.62, Max Score: 39.40, Min Score: 25.17, Time per Episode: 87.34\n",
      "Epsilon: 0.9707815999991598 and Memory size: 730800\n",
      "Episode 74, Average Score: 23.79, Max Score: 39.44, Min Score: 32.57, Time per Episode: 88.79\n",
      "Epsilon: 0.9703807999991483 and Memory size: 740800\n",
      "Episode 75, Average Score: 23.95, Max Score: 39.13, Min Score: 30.43, Time per Episode: 88.70\n",
      "Epsilon: 0.9699799999991368 and Memory size: 750800\n",
      "Episode 76, Average Score: 24.11, Max Score: 39.05, Min Score: 29.16, Time per Episode: 87.01\n",
      "Epsilon: 0.9695791999991252 and Memory size: 760800\n",
      "Episode 77, Average Score: 24.27, Max Score: 39.59, Min Score: 31.13, Time per Episode: 90.03\n",
      "Epsilon: 0.9691783999991137 and Memory size: 770800\n",
      "Episode 78, Average Score: 24.43, Max Score: 39.55, Min Score: 33.28, Time per Episode: 89.60\n",
      "Epsilon: 0.9687775999991022 and Memory size: 780800\n",
      "Episode 79, Average Score: 24.60, Max Score: 39.10, Min Score: 34.97, Time per Episode: 90.64\n",
      "Epsilon: 0.9683767999990907 and Memory size: 790800\n",
      "Episode 80, Average Score: 24.76, Max Score: 39.56, Min Score: 31.65, Time per Episode: 89.49\n",
      "Epsilon: 0.9679759999990791 and Memory size: 800800\n",
      "Episode 81, Average Score: 24.92, Max Score: 39.51, Min Score: 33.41, Time per Episode: 89.69\n",
      "Epsilon: 0.9675759999990676 and Memory size: 810820\n",
      "Episode 82, Average Score: 25.08, Max Score: 39.65, Min Score: 33.82, Time per Episode: 91.26\n",
      "Epsilon: 0.9671759999990561 and Memory size: 820840\n",
      "Episode 83, Average Score: 25.23, Max Score: 39.47, Min Score: 32.59, Time per Episode: 90.59\n",
      "Epsilon: 0.9667759999990446 and Memory size: 830860\n",
      "Episode 84, Average Score: 25.37, Max Score: 39.42, Min Score: 33.49, Time per Episode: 94.89\n",
      "Epsilon: 0.9663759999990331 and Memory size: 840880\n",
      "Episode 85, Average Score: 25.51, Max Score: 39.53, Min Score: 35.10, Time per Episode: 91.76\n",
      "Epsilon: 0.9659759999990216 and Memory size: 850900\n",
      "Episode 86, Average Score: 25.65, Max Score: 39.39, Min Score: 34.81, Time per Episode: 89.20\n",
      "Epsilon: 0.9655759999990101 and Memory size: 860920\n",
      "Episode 87, Average Score: 25.79, Max Score: 39.51, Min Score: 33.50, Time per Episode: 89.47\n",
      "Epsilon: 0.9651759999989986 and Memory size: 870940\n",
      "Episode 88, Average Score: 25.93, Max Score: 39.23, Min Score: 34.83, Time per Episode: 91.85\n",
      "Epsilon: 0.9647759999989871 and Memory size: 880960\n",
      "Episode 89, Average Score: 26.06, Max Score: 39.07, Min Score: 35.05, Time per Episode: 93.09\n",
      "Epsilon: 0.9643759999989756 and Memory size: 890980\n",
      "Episode 90, Average Score: 26.19, Max Score: 39.50, Min Score: 32.55, Time per Episode: 93.51\n",
      "Epsilon: 0.9639759999989641 and Memory size: 901000\n",
      "Episode 91, Average Score: 26.31, Max Score: 39.41, Min Score: 33.34, Time per Episode: 93.59\n",
      "Epsilon: 0.9635751999989526 and Memory size: 911000\n",
      "Episode 92, Average Score: 26.43, Max Score: 39.53, Min Score: 31.95, Time per Episode: 95.15\n",
      "Epsilon: 0.963174399998941 and Memory size: 921000\n",
      "Episode 93, Average Score: 26.55, Max Score: 39.45, Min Score: 34.72, Time per Episode: 96.40\n",
      "Epsilon: 0.9627735999989295 and Memory size: 931000\n",
      "Episode 94, Average Score: 26.66, Max Score: 39.54, Min Score: 33.45, Time per Episode: 96.27\n",
      "Epsilon: 0.962372799998918 and Memory size: 941000\n",
      "Episode 95, Average Score: 26.76, Max Score: 39.61, Min Score: 32.53, Time per Episode: 95.58\n",
      "Epsilon: 0.9619719999989065 and Memory size: 951000\n",
      "Episode 96, Average Score: 26.87, Max Score: 39.60, Min Score: 33.47, Time per Episode: 96.51\n",
      "Epsilon: 0.961571199998895 and Memory size: 961000\n",
      "Episode 97, Average Score: 26.96, Max Score: 39.15, Min Score: 31.93, Time per Episode: 96.22\n",
      "Epsilon: 0.9611703999988834 and Memory size: 971000\n",
      "Episode 98, Average Score: 27.06, Max Score: 38.64, Min Score: 33.20, Time per Episode: 96.86\n",
      "Epsilon: 0.9607695999988719 and Memory size: 981000\n",
      "Episode 99, Average Score: 27.16, Max Score: 38.84, Min Score: 33.49, Time per Episode: 100.65\n",
      "Epsilon: 0.9603687999988604 and Memory size: 991000\n",
      "Episode 100, Average Score: 27.25, Max Score: 39.42, Min Score: 28.92, Time per Episode: 99.16\n",
      "Epsilon: 0.9599679999988489 and Memory size: 1000000\n",
      "Episode 101, Average Score: 27.62, Max Score: 39.39, Min Score: 34.55, Time per Episode: 95.76\n",
      "Epsilon: 0.9595679999988374 and Memory size: 1000000\n",
      "Episode 102, Average Score: 27.98, Max Score: 39.16, Min Score: 31.67, Time per Episode: 93.92\n",
      "Epsilon: 0.9591679999988258 and Memory size: 1000000\n",
      "Episode 103, Average Score: 28.35, Max Score: 39.29, Min Score: 35.35, Time per Episode: 94.14\n",
      "Epsilon: 0.9587679999988143 and Memory size: 1000000\n",
      "Episode 104, Average Score: 28.71, Max Score: 39.17, Min Score: 34.89, Time per Episode: 94.25\n",
      "Epsilon: 0.9583679999988028 and Memory size: 1000000\n",
      "Episode 105, Average Score: 29.06, Max Score: 39.44, Min Score: 29.96, Time per Episode: 94.24\n",
      "Epsilon: 0.9579679999987913 and Memory size: 1000000\n",
      "Episode 106, Average Score: 29.41, Max Score: 39.42, Min Score: 31.99, Time per Episode: 94.34\n",
      "Epsilon: 0.9575679999987798 and Memory size: 1000000\n",
      "Episode 107, Average Score: 29.75, Max Score: 39.16, Min Score: 29.89, Time per Episode: 94.29\n",
      "Epsilon: 0.9571679999987683 and Memory size: 1000000\n",
      "Episode 108, Average Score: 30.09, Max Score: 39.32, Min Score: 32.63, Time per Episode: 93.86\n",
      "Epsilon: 0.9567679999987568 and Memory size: 1000000\n",
      "Episode 109, Average Score: 30.43, Max Score: 38.08, Min Score: 28.78, Time per Episode: 94.51\n",
      "Epsilon: 0.9563679999987453 and Memory size: 1000000\n",
      "Episode 110, Average Score: 30.75, Max Score: 38.44, Min Score: 31.93, Time per Episode: 96.26\n",
      "Epsilon: 0.9559679999987338 and Memory size: 1000000\n",
      "Episode 111, Average Score: 31.09, Max Score: 39.53, Min Score: 33.91, Time per Episode: 97.03\n",
      "Epsilon: 0.9555671999987223 and Memory size: 1000000\n",
      "Episode 112, Average Score: 31.43, Max Score: 39.40, Min Score: 35.87, Time per Episode: 98.34\n",
      "Epsilon: 0.9551663999987108 and Memory size: 1000000\n",
      "Episode 113, Average Score: 31.77, Max Score: 39.35, Min Score: 35.99, Time per Episode: 99.99\n",
      "Epsilon: 0.9547655999986993 and Memory size: 1000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 114, Average Score: 32.10, Max Score: 39.45, Min Score: 35.56, Time per Episode: 100.83\n",
      "Epsilon: 0.9543647999986877 and Memory size: 1000000\n",
      "Episode 115, Average Score: 32.41, Max Score: 38.81, Min Score: 33.56, Time per Episode: 100.87\n",
      "Epsilon: 0.9539639999986762 and Memory size: 1000000\n",
      "Episode 116, Average Score: 32.73, Max Score: 39.37, Min Score: 35.42, Time per Episode: 101.19\n",
      "Epsilon: 0.9535631999986647 and Memory size: 1000000\n",
      "Episode 117, Average Score: 33.04, Max Score: 39.50, Min Score: 34.40, Time per Episode: 97.45\n",
      "Epsilon: 0.9531623999986532 and Memory size: 1000000\n",
      "Episode 118, Average Score: 33.32, Max Score: 38.88, Min Score: 32.81, Time per Episode: 97.33\n",
      "Epsilon: 0.9527615999986416 and Memory size: 1000000\n",
      "Episode 119, Average Score: 33.58, Max Score: 39.59, Min Score: 27.93, Time per Episode: 97.67\n",
      "Epsilon: 0.9523607999986301 and Memory size: 1000000\n",
      "Episode 120, Average Score: 33.86, Max Score: 39.65, Min Score: 24.67, Time per Episode: 97.47\n",
      "Epsilon: 0.9519599999986186 and Memory size: 1000000\n",
      "Episode 121, Average Score: 34.11, Max Score: 39.46, Min Score: 31.27, Time per Episode: 97.39\n",
      "Epsilon: 0.9515599999986071 and Memory size: 1000000\n",
      "Episode 122, Average Score: 34.34, Max Score: 39.37, Min Score: 21.71, Time per Episode: 97.32\n",
      "Epsilon: 0.9511599999985956 and Memory size: 1000000\n",
      "Episode 123, Average Score: 34.58, Max Score: 39.48, Min Score: 30.72, Time per Episode: 96.56\n",
      "Epsilon: 0.9507599999985841 and Memory size: 1000000\n",
      "Episode 124, Average Score: 34.77, Max Score: 39.27, Min Score: 26.64, Time per Episode: 96.78\n",
      "Epsilon: 0.9503599999985726 and Memory size: 1000000\n",
      "Episode 125, Average Score: 34.95, Max Score: 39.25, Min Score: 19.89, Time per Episode: 97.19\n",
      "Epsilon: 0.9499599999985611 and Memory size: 1000000\n",
      "Episode 126, Average Score: 35.12, Max Score: 39.31, Min Score: 14.34, Time per Episode: 97.25\n",
      "Epsilon: 0.9495599999985496 and Memory size: 1000000\n",
      "Done!!\n"
     ]
    }
   ],
   "source": [
    "NUMBER_TRAINING_GAMES = 2000\n",
    "saved_models_folder = \"\"\n",
    "\n",
    "# with active_session():\n",
    "agent = Agent(state_size=state_size, action_size=action_size, random_seed=2, number_agents=num_agents)\n",
    "\n",
    "def ddpg(number_episodes=NUMBER_TRAINING_GAMES, max_t=300, print_every=1):\n",
    "    scores_deque = deque(maxlen=100)\n",
    "    scores = []\n",
    "    all_average_scores = []\n",
    "    all_scores = []\n",
    "    for i_episode in range(1, number_episodes + 1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name]  # reset the environment\n",
    "        states = env_info.vector_observations  # get the current state (for each agent)\n",
    "        agent.reset()\n",
    "        state = states[0]\n",
    "        scores = np.zeros(num_agents)  # initialize the score (for each agent)\n",
    "        score = 0\n",
    "        step = 0\n",
    "\n",
    "        start_timestep = time.time()\n",
    "        while True:\n",
    "            # for t in range(max_t):\n",
    "            actions = agent.act(states)\n",
    "            env_info = env.step(actions)[brain_name]\n",
    "            next_states = env_info.vector_observations\n",
    "            rewards = env_info.rewards\n",
    "            dones = env_info.local_done\n",
    "            agent.step(states, actions, rewards, next_states, dones)\n",
    "            states = next_states\n",
    "\n",
    "            score += np.array(rewards)\n",
    "            scores += rewards\n",
    "            step +=1\n",
    "\n",
    "            if any(dones):\n",
    "                break\n",
    "\n",
    "        # scores_deque.append(np.mean(score))\n",
    "        score = np.mean(scores)\n",
    "        scores_deque.append(score)\n",
    "        all_scores.append(score)\n",
    "        average_score = np.mean(scores_deque)\n",
    "\n",
    "        all_average_scores.append(average_score)\n",
    "        # scores.append(np.mean(score))\n",
    "        print('\\rEpisode {}, Average Score: {:.2f}, Max Score: {:.2f}, Min Score: {:.2f}, Time per Episode: {:.2f}' \\\n",
    "              .format(i_episode, average_score, np.max(scores), np.min(scores), time.time() - start_timestep), end=\"\\n\")\n",
    "        print('Epsilon: {} and Memory size: {}'.format(agent.eps, len(agent.memory)))\n",
    "        torch.save(agent.actor_local.state_dict(), saved_models_folder + 'checkpoint_actor.pth')\n",
    "        torch.save(agent.critic_local.state_dict(), saved_models_folder + 'checkpoint_critic.pth')\n",
    "\n",
    "        if i_episode == 1 or best_mean_score < average_score:\n",
    "            best_mean_score = average_score\n",
    "            torch.save(agent.actor_local.state_dict(), saved_models_folder + 'actor_local{}.pth'.format(int(best_mean_score)))\n",
    "            torch.save(agent.critic_local.state_dict(), saved_models_folder + 'critic_local{}.pth'.format(int(best_mean_score)))\n",
    "            torch.save(agent.actor_local.state_dict(), saved_models_folder + 'best_actor_model.pth')\n",
    "            torch.save(agent.critic_local.state_dict(), saved_models_folder + 'best_critic_model.pth')\n",
    "\n",
    "        if i_episode % print_every == 0:\n",
    "            if len(scores_deque) == 100 and np.mean(scores_deque) >= 35:\n",
    "                print('Done!!')\n",
    "                break\n",
    "\n",
    "    return all_average_scores, all_scores\n",
    "\n",
    "average_scores, scores = ddpg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "# plot performance\n",
    "line1, = plt.plot([i for i in range(len(scores))], np.asarray(scores), color=\"blue\", label='Episode Score')\n",
    "line2, = plt.plot([i for i in range(len(average_scores))], list(average_scores), color=\"red\", label='Average Score')\n",
    "\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.legend(handles=[line1, line2], loc=4)\n",
    "plt.show()\n",
    "plt.savefig(saved_models_folder + \"continuous_control_training_performance.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
